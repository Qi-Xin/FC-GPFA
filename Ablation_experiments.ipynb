{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "# Test if GPU is available\n",
    "# Note that CUDA below 12.1 can have bugs\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "# print(torch.cuda.get_device_name(0))\n",
    "print(torch.version.cuda)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% import libraries\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "from numpy.fft import fft as fft\n",
    "from numpy.fft import ifft as ifft\n",
    "import pickle\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.manifold import TSNE\n",
    "import scipy.stats\n",
    "from scipy.stats import wilcoxon, chi2\n",
    "import scipy.interpolate \n",
    "import scipy.signal\n",
    "from scipy import linalg\n",
    "from scipy.special import rel_entr\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import logging\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.genmod.generalized_linear_model as smm\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qix/anaconda3/envs/allen/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import my code\n",
    "import utility_functions as utils\n",
    "import GLM\n",
    "from DataLoader import Allen_dataset, Allen_dataloader_multi_session, Simple_dataloader_from_spikes\n",
    "from model_trainer import Trainer\n",
    "\n",
    "utils.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GLM neuron dataset\n",
    "file_name = '/home/qix/user_data/EIF_simulation_dataset/synthetic_data_GLM.npz'\n",
    "data = np.load(file_name)\n",
    "spikes = data['spikes'][:,:,:]\n",
    "nneuron = spikes.shape[1]//2\n",
    "synthetic_GLM_dataloader = Simple_dataloader_from_spikes(\n",
    "    [spikes[:,:nneuron,:], spikes[:,nneuron:,:]],\n",
    "    npadding=50,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.1,\n",
    "    batch_size=64,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Load EIF neuron dataset\n",
    "file_name = f'/home/qix/user_data/EIF_simulation_dataset/synthetic_data_EIF_connTrue.npz'\n",
    "data = np.load(file_name, allow_pickle=True)\n",
    "spikes = data['spikes'][:,:,:]\n",
    "nneuron = spikes.shape[1]//2\n",
    "synthetic_EIF_dataloader = Simple_dataloader_from_spikes(\n",
    "    [spikes[:,:nneuron,:], spikes[:,nneuron:,:]],\n",
    "    npadding=50,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.1,\n",
    "    batch_size=64,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Load real dataset\n",
    "if sys.platform == 'linux':\n",
    "    data_path = '/home/qix/user_data/allen_spike_trains/single_sessions.joblib'\n",
    "else:\n",
    "    data_path = 'D:/ecephys_cache_dir/single_sessions.joblib'\n",
    "real_dataloader = joblib.load(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qix/anaconda3/envs/allen/lib/python3.9/site-packages/allensdk/brain_observatory/ecephys/ecephys_session.py:1371: UserWarning: Session includes invalid time intervals that could be accessed with the attribute 'invalid_times',Spikes within these intervals are invalid and may need to be excluded from the analysis.\n",
      "  warnings.warn(\"Session includes invalid time intervals that could \"\n"
     ]
    }
   ],
   "source": [
    "spikes = np.zeros((250, 352, 132*64))\n",
    "trial_idx = 0\n",
    "for batch in real_dataloader.train_loader:\n",
    "    spikes[:, :, trial_idx:trial_idx+batch['spike_trains'].shape[2]] = batch['spike_trains']\n",
    "    trial_idx += batch['spike_trains'].shape[2]\n",
    "acc_nneuron = [0] + list(np.cumsum(real_dataloader.sessions[757216464].nneuron_list))\n",
    "\n",
    "real_dataloader_fast = Simple_dataloader_from_spikes(\n",
    "    [spikes[:,acc_nneuron[i]:acc_nneuron[i+1],:] for i in range(len(acc_nneuron)-1)],\n",
    "    npadding=50,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.1,\n",
    "    batch_size=64,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for all ablation experiments\n",
    "verbose = False\n",
    "# datasets = [synthetic_GLM_dataloader, synthetic_EIF_dataloader]\n",
    "datasets = [synthetic_GLM_dataloader, synthetic_EIF_dataloader, real_dataloader_fast]\n",
    "nrep = 5\n",
    "ckp_path = '/home/qix/user_data/VAETransformer_checkpoint_ablation'\n",
    "\n",
    "params_set = {}\n",
    "params_set[0] = {\n",
    "    # B-spline basis\n",
    "    'num_B_spline_basis': 10,\n",
    "    # Transformer VAE's settings\n",
    "    'downsample_factor': 10,\n",
    "    'transformer_num_layers': 2,\n",
    "    'transformer_d_model': 128,\n",
    "    'transformer_dim_feedforward': 512,\n",
    "    'transformer_vae_output_dim': 8,\n",
    "    'transformer_dropout': 0.0,\n",
    "    'transformer_nhead': 1,\n",
    "    'stimulus_nfactor': 2,\n",
    "    'stimulus_decoder_inter_dim_factor': 2,\n",
    "    'beta': 1.0,\n",
    "    'use_area_specific_decoder': True,\n",
    "    'use_area_specific_encoder': True,\n",
    "    'use_cls': False,\n",
    "    # Coupling's settings\n",
    "    'coupling_basis_peaks_max': 7,\n",
    "    'coupling_basis_num': 3,\n",
    "    'coupling_nsubspace': 1,\n",
    "    'use_self_coupling': True,\n",
    "    # Coupling strength latent's settings\n",
    "    'K_sigma2': 1.0,\n",
    "    'K_tau': 100,\n",
    "    'coupling_strength_nlatent': 1,\n",
    "    # Self-history's settings\n",
    "    'self_history_basis_peaks_max': 2,\n",
    "    'self_history_basis_num': 3,\n",
    "    'self_history_basis_nonlinear': 0.7,\n",
    "    # Penalty settings\n",
    "    'penalty_smoothing_spline': 1e3,\n",
    "    'penalty_coupling_subgroup': 1e-5,\n",
    "    'penalty_diff_loading': None,\n",
    "    'penalty_loading_similarity': None,\n",
    "    # Training settings\n",
    "    'batch_size': 64,\n",
    "    'sample_latent': False,\n",
    "    'lr': 1e-3,\n",
    "    'epoch_warm_up': 0,\n",
    "    'epoch_patience': 3,\n",
    "    'epoch_max': 200,\n",
    "    'tol': 1e-5,\n",
    "    'weight_decay': 0,\n",
    "    'lr_transformer': 1e-4,\n",
    "    'lr_sti': 1e-2,\n",
    "    'lr_cp': 1e-2,\n",
    "    'lr_self_history': 1e-2,\n",
    "}\n",
    "\n",
    "params_set[1] = {\n",
    "    # B-spline basis\n",
    "    'num_B_spline_basis': 20,\n",
    "    # Transformer VAE's settings\n",
    "    'downsample_factor': 10,\n",
    "    'transformer_num_layers': 2,\n",
    "    'transformer_d_model': 128,\n",
    "    'transformer_dim_feedforward': 512,\n",
    "    'transformer_vae_output_dim': 16,\n",
    "    'transformer_dropout': 0.0,\n",
    "    'transformer_nhead': 1,\n",
    "    'stimulus_nfactor': 1,\n",
    "    'stimulus_decoder_inter_dim_factor': 2,\n",
    "    'beta': 1.0,\n",
    "    'use_area_specific_decoder': True,\n",
    "    'use_area_specific_encoder': True,\n",
    "    'use_cls': False,\n",
    "    # Coupling's settings\n",
    "    'coupling_basis_peaks_max': 5,\n",
    "    'coupling_basis_num': 3,\n",
    "    'coupling_nsubspace': 1,\n",
    "    'use_self_coupling': True,\n",
    "    # Coupling strength latent's settings\n",
    "    'K_sigma2': 1.0,\n",
    "    'K_tau': 100,\n",
    "    'coupling_strength_nlatent': 1,\n",
    "    # Self-history's settings\n",
    "    'self_history_basis_peaks_max': 1.5,\n",
    "    'self_history_basis_num': 3,\n",
    "    'self_history_basis_nonlinear': 1,\n",
    "    # Penalty settings\n",
    "    'penalty_smoothing_spline': 1e3,\n",
    "    'penalty_coupling_subgroup': 1e-5,\n",
    "    'penalty_diff_loading': None,\n",
    "    'penalty_loading_similarity': None,\n",
    "    # Training settings\n",
    "    'batch_size': 64,\n",
    "    'sample_latent': False,\n",
    "    'lr': 1e-3,\n",
    "    'epoch_warm_up': 0,\n",
    "    'epoch_patience': 3,\n",
    "    'epoch_max': 200,\n",
    "    'tol': 1e-5,\n",
    "    'weight_decay': 0,\n",
    "    'lr_transformer': 1e-4,\n",
    "    'lr_sti': 1e-2,\n",
    "    'lr_cp': 1e-2,\n",
    "    'lr_self_history': 1e-2,\n",
    "}\n",
    "\n",
    "params_set[2] = {\n",
    "    # B-spline basis\n",
    "    'num_B_spline_basis': 10,\n",
    "    # Transformer VAE's settings\n",
    "    'downsample_factor': 10,\n",
    "    'transformer_num_layers': 2,\n",
    "    'transformer_d_model': 128,\n",
    "    'transformer_dim_feedforward': 512,\n",
    "    'transformer_vae_output_dim': 12,\n",
    "    'transformer_dropout': 0.0,\n",
    "    'transformer_nhead': 1,\n",
    "    'stimulus_nfactor': 2,\n",
    "    'stimulus_decoder_inter_dim_factor': 2,\n",
    "    'beta': 1.0,\n",
    "    'use_area_specific_decoder': True,\n",
    "    'use_area_specific_encoder': True,\n",
    "    'use_cls': False,\n",
    "    # Coupling's settings\n",
    "    'coupling_basis_peaks_max': 7,\n",
    "    'coupling_basis_num': 3,\n",
    "    'coupling_nsubspace': 1,\n",
    "    'use_self_coupling': True,\n",
    "    # Coupling strength latent's settings\n",
    "    'K_sigma2': 1.0,\n",
    "    'K_tau': 100,\n",
    "    'coupling_strength_nlatent': 1,\n",
    "    # Self-history's settings\n",
    "    'self_history_basis_peaks_max': 1.5,\n",
    "    'self_history_basis_num': 3,\n",
    "    'self_history_basis_nonlinear': 1,\n",
    "    # Penalty settings\n",
    "    'penalty_smoothing_spline': 1e3,\n",
    "    'penalty_coupling_subgroup': 1e-5,\n",
    "    'penalty_diff_loading': None,\n",
    "    'penalty_loading_similarity': None,\n",
    "    # Training settings\n",
    "    'batch_size': 64,\n",
    "    'sample_latent': False,\n",
    "    'lr': 1e-3,\n",
    "    'epoch_warm_up': 0,\n",
    "    'epoch_patience': 3,\n",
    "    'epoch_max': 50,\n",
    "    'tol': 1e-5,\n",
    "    'weight_decay': 0,\n",
    "    'lr_transformer': 1e-4,\n",
    "    'lr_sti': 1e-2,\n",
    "    'lr_cp': 1e-2,\n",
    "    'lr_self_history': 1e-2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sessions: 1, Batch size: 64, Train set size: 132, Val set size: 20, Test set size: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qix/anaconda3/envs/allen/lib/python3.9/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4155245/903259363.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0midata\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mirep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_use\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckp_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# First step: train the model with a trial-invariant stimulus effect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         trainer.train(\n",
      "\u001b[0;32m~/FC-GPFA/model_trainer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, verbose, record_results, include_stimulus, include_coupling, include_self_history, fix_stimulus, fix_latents)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_latent'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mtrain_loss_wo_penalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mtotal_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 firing_rate = self.model(\n",
      "\u001b[0;32m~/anaconda3/envs/allen/lib/python3.9/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;31m# If the bar is disabled, then just walk the iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;31m# (note: keep this check outside the loop for performance)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FC-GPFA/DataLoader.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_batch_idx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{self.split}_batches\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         batch = self.dataloader.get_batch(current_batch_idx=self.current_batch_idx,\n\u001b[0m\u001b[1;32m     37\u001b[0m                                           split=self.split)\n\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_batch_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FC-GPFA/DataLoader.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, current_batch_idx, split, include_behavior)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid split: {split}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         batch = self._load_batch(batches[current_batch_idx], \n\u001b[0m\u001b[1;32m    297\u001b[0m                                  include_behavior=include_behavior)\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FC-GPFA/DataLoader.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, batch_indices, include_behavior)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;31m# Get session ID and local trial indices for each trial in the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0msession_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession_idx_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_session_for_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mlocal_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_indices\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msession_idx_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mcurrent_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msession_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trial_spike_trains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spike_trains'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spike_trains'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'session_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nneuron_list'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnneuron_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FC-GPFA/DataLoader.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, selected_trials, dt)\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;31m# Group spikes by neuron and trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0mgrouped_spikes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspikes_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unit_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stimulus_presentation_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;31m# Fill spike train array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0munit_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstim_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouped_spikes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m             \u001b[0mneuron_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneuron_idx_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munit_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m             \u001b[0mtrial_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial_idx_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstim_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mspike_times\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time_since_stimulus_presentation_onset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/allen/lib/python3.9/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, data, axis)\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \"\"\"\n\u001b[1;32m    788\u001b[0m         \u001b[0msplitter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_splitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_keys_seq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/allen/lib/python3.9/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m         \u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1332\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/allen/lib/python3.9/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, sdata, slice_obj)\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0;31m#     return sdata.iloc[slice_obj]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m         \u001b[0;31m# else:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \u001b[0;31m#     return sdata.iloc[:, slice_obj]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m         \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1358\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1359\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"groupby\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/allen/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0;31m# first check if a Manager is passed without any other arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0;31m# -> use fastpath (without checking Manager type)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0;31m# GH#33357 fastpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m                 \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0mmanager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode.data_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/allen/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, data, copy, attrs)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattrs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_attrs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_flags\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallows_duplicate_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Full model\n",
    "results_ablation = np.zeros((len(datasets), nrep))\n",
    "\n",
    "for idata, data_to_use in enumerate(datasets):\n",
    "    for irep in range(nrep):\n",
    "\n",
    "        trainer = Trainer(data_to_use, ckp_path, params_set[idata])\n",
    "        \n",
    "        # First step: train the model with a trial-invariant stimulus effect\n",
    "        trainer.train(\n",
    "            include_stimulus=True,\n",
    "            include_coupling=False,\n",
    "            include_self_history=False,\n",
    "            fix_stimulus=True,\n",
    "            fix_latents=True,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        # Second step: train the model with a trial-varying stimulus effect\n",
    "        # trainer.make_optimizer(frozen_params=['sti_readout'])\n",
    "        trainer.make_optimizer(frozen_params=['sti_inhomo', ]) # We are fixing the trial-invariant stimulus effect\n",
    "        trainer.train(\n",
    "            include_stimulus=True,\n",
    "            include_coupling=False,\n",
    "            include_self_history=False,\n",
    "            fix_stimulus=False,\n",
    "            fix_latents=True,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "        trainer.make_optimizer(frozen_params=['transformer_encoder', 'to_latent', 'token_converter'])\n",
    "        # trainer.make_optimizer(frozen_params=[])\n",
    "        trainer.train(\n",
    "            include_stimulus=True,\n",
    "            include_coupling=True,\n",
    "            include_self_history=False,\n",
    "            fix_stimulus=False,\n",
    "            fix_latents=True,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "        # trainer.make_optimizer(frozen_params=['transformer_encoder', 'to_latent', 'token_converter'])\n",
    "        trainer.make_optimizer(frozen_params=['transformer_encoder', 'to_latent', 'token_converter',\n",
    "            'sti_readout', 'sti_decoder', 'sti_inhomo', 'cp_latents_readout', 'cp_time_varying_coef_offset', \n",
    "            'cp_beta_coupling', 'cp_weight_sending', 'cp_weight_receiving'])\n",
    "        # trainer.make_optimizer(frozen_params=[])\n",
    "        test_loss = trainer.train(\n",
    "            include_stimulus=True,\n",
    "            include_coupling=True,\n",
    "            include_self_history=True,\n",
    "            fix_stimulus=False,\n",
    "            fix_latents=True,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "        results_ablation[idata, irep] = test_loss\n",
    "\n",
    "np.save('/home/qix/user_data/EIF_simulation_dataset/results_ablation_full_model.npy', results_ablation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 44/200 [00:03<00:12, 12.47it/s]\n",
      " 10%|█         | 21/200 [00:02<00:18,  9.42it/s]\n",
      " 30%|███       | 60/200 [00:07<00:17,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 50/200 [00:04<00:12, 12.45it/s]\n",
      " 52%|█████▎    | 105/200 [00:13<00:12,  7.80it/s]\n",
      " 28%|██▊       | 56/200 [00:06<00:16,  8.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 49/200 [00:04<00:12, 12.01it/s]\n",
      " 32%|███▏      | 63/200 [00:08<00:17,  7.80it/s]\n",
      " 29%|██▉       | 58/200 [00:06<00:16,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 53/200 [00:03<00:11, 13.31it/s]\n",
      " 28%|██▊       | 57/200 [00:06<00:16,  8.81it/s]\n",
      " 29%|██▉       | 58/200 [00:06<00:15,  8.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 48/200 [00:03<00:12, 12.02it/s]\n",
      " 30%|███       | 60/200 [00:07<00:17,  7.92it/s]\n",
      " 30%|██▉       | 59/200 [00:07<00:17,  8.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 69/200 [00:04<00:09, 14.44it/s]\n",
      " 18%|█▊        | 37/200 [00:04<00:20,  8.04it/s]\n",
      " 28%|██▊       | 57/200 [00:07<00:18,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 68/200 [00:05<00:09, 13.32it/s]\n",
      " 19%|█▉        | 38/200 [00:04<00:20,  7.86it/s]\n",
      " 28%|██▊       | 57/200 [00:06<00:15,  9.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 62/200 [00:04<00:09, 14.77it/s]\n",
      " 34%|███▎      | 67/200 [00:07<00:15,  8.75it/s]\n",
      " 28%|██▊       | 55/200 [00:06<00:16,  8.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 61/200 [00:04<00:10, 13.47it/s]\n",
      " 19%|█▉        | 38/200 [00:04<00:19,  8.34it/s]\n",
      " 28%|██▊       | 56/200 [00:07<00:18,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 67/200 [00:05<00:11, 11.69it/s]\n",
      " 15%|█▌        | 30/200 [00:02<00:16, 10.46it/s]\n",
      " 28%|██▊       | 55/200 [00:06<00:17,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [00:20<00:11,  1.57it/s]\n",
      " 54%|█████▍    | 27/50 [00:35<00:30,  1.31s/it]\n",
      " 32%|███▏      | 16/50 [00:21<00:46,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [00:21<00:11,  1.51it/s]\n",
      " 46%|████▌     | 23/50 [00:30<00:35,  1.33s/it]\n",
      " 32%|███▏      | 16/50 [00:21<00:45,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [00:19<00:11,  1.62it/s]\n",
      " 28%|██▊       | 14/50 [00:18<00:48,  1.35s/it]\n",
      " 32%|███▏      | 16/50 [00:21<00:46,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [00:20<00:10,  1.61it/s]\n",
      " 56%|█████▌    | 28/50 [00:36<00:28,  1.31s/it]\n",
      " 32%|███▏      | 16/50 [00:21<00:45,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [00:18<00:09,  1.78it/s]\n",
      " 68%|██████▊   | 34/50 [00:45<00:21,  1.35s/it]\n",
      " 26%|██▌       | 13/50 [00:17<00:50,  1.36s/it]\n"
     ]
    }
   ],
   "source": [
    "# Without Transformer encoder model\n",
    "results_ablation = np.zeros((len(datasets), nrep))\n",
    "\n",
    "for idata, data_to_use in enumerate(datasets):\n",
    "    for irep in range(nrep):\n",
    "\n",
    "        trainer = Trainer(data_to_use, ckp_path, params_set[idata])\n",
    "        \n",
    "        # First step: train the model with a trial-invariant stimulus effect\n",
    "        trainer.train(\n",
    "            include_stimulus=True,\n",
    "            include_coupling=False,\n",
    "            include_self_history=False,\n",
    "            fix_stimulus=True,\n",
    "            fix_latents=True,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "        trainer.make_optimizer(frozen_params=['transformer_encoder', 'to_latent', 'token_converter'])\n",
    "        # trainer.make_optimizer(frozen_params=[])\n",
    "        trainer.train(\n",
    "            include_stimulus=True,\n",
    "            include_coupling=True,\n",
    "            include_self_history=False,\n",
    "            fix_stimulus=False,\n",
    "            fix_latents=True,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "        # trainer.make_optimizer(frozen_params=['transformer_encoder', 'to_latent', 'token_converter'])\n",
    "        trainer.make_optimizer(frozen_params=['transformer_encoder', 'to_latent', 'token_converter',\n",
    "            'sti_readout', 'sti_decoder', 'sti_inhomo', 'cp_latents_readout', 'cp_time_varying_coef_offset', \n",
    "            'cp_beta_coupling', 'cp_weight_sending', 'cp_weight_receiving'])\n",
    "        # trainer.make_optimizer(frozen_params=[])\n",
    "        test_loss = trainer.train(\n",
    "            include_stimulus=True,\n",
    "            include_coupling=True,\n",
    "            include_self_history=True,\n",
    "            fix_stimulus=False,\n",
    "            fix_latents=True,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "        results_ablation[idata, irep] = test_loss\n",
    "\n",
    "np.save('/home/qix/user_data/EIF_simulation_dataset/results_ablation_wo_encoder.npy', results_ablation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 51/200 [00:04<00:13, 11.27it/s]\n",
      "  6%|▌         | 12/200 [00:01<00:20,  9.37it/s]\n",
      " 38%|███▊      | 75/200 [00:07<00:12,  9.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 42/200 [00:03<00:12, 12.74it/s]\n",
      " 38%|███▊      | 76/200 [00:08<00:13,  9.48it/s]\n",
      " 30%|██▉       | 59/200 [00:06<00:14,  9.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 47/200 [00:03<00:11, 13.86it/s]\n",
      " 18%|█▊        | 35/200 [00:04<00:19,  8.26it/s]\n",
      " 36%|███▌      | 72/200 [00:06<00:12, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 54/200 [00:04<00:12, 11.62it/s]\n",
      " 38%|███▊      | 76/200 [00:08<00:13,  8.87it/s]\n",
      " 32%|███▏      | 63/200 [00:06<00:14,  9.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 56/200 [00:04<00:11, 12.73it/s]\n",
      " 43%|████▎     | 86/200 [00:08<00:10, 10.39it/s]\n",
      " 32%|███▏      | 63/200 [00:06<00:13, 10.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 78/200 [00:06<00:09, 12.28it/s]\n",
      " 17%|█▋        | 34/200 [00:03<00:17,  9.48it/s]\n",
      " 29%|██▉       | 58/200 [00:06<00:15,  9.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 71/200 [00:05<00:10, 12.27it/s]\n",
      " 20%|█▉        | 39/200 [00:03<00:16,  9.78it/s]\n",
      " 27%|██▋       | 54/200 [00:05<00:14,  9.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 64/200 [00:05<00:10, 12.73it/s]\n",
      " 26%|██▋       | 53/200 [00:05<00:16,  9.14it/s]\n",
      " 28%|██▊       | 57/200 [00:06<00:15,  9.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 62/200 [00:04<00:09, 13.98it/s]\n",
      " 24%|██▎       | 47/200 [00:05<00:17,  8.94it/s]\n",
      " 28%|██▊       | 57/200 [00:05<00:14,  9.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 70/200 [00:05<00:10, 12.19it/s]\n",
      " 18%|█▊        | 35/200 [00:03<00:16, 10.12it/s]\n",
      " 28%|██▊       | 56/200 [00:05<00:13, 10.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [00:20<00:11,  1.58it/s]\n",
      " 94%|█████████▍| 47/50 [00:39<00:02,  1.18it/s]\n",
      " 28%|██▊       | 14/50 [00:12<00:33,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [00:20<00:11,  1.57it/s]\n",
      " 76%|███████▌  | 38/50 [00:31<00:09,  1.20it/s]\n",
      " 34%|███▍      | 17/50 [00:14<00:28,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [00:19<00:10,  1.69it/s]\n",
      " 76%|███████▌  | 38/50 [00:32<00:10,  1.15it/s]\n",
      " 34%|███▍      | 17/50 [00:14<00:28,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [00:21<00:11,  1.53it/s]\n",
      " 90%|█████████ | 45/50 [00:38<00:04,  1.16it/s]\n",
      " 32%|███▏      | 16/50 [00:13<00:28,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [00:20<00:11,  1.60it/s]\n",
      " 50%|█████     | 25/50 [00:22<00:22,  1.12it/s]\n",
      " 34%|███▍      | 17/50 [00:14<00:27,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# Without coupling\n",
    "results_ablation = np.zeros((len(datasets), nrep))\n",
    "\n",
    "for idata, data_to_use in enumerate(datasets):\n",
    "    for irep in range(nrep):\n",
    "\n",
    "        trainer = Trainer(data_to_use, ckp_path, params_set[idata])\n",
    "        \n",
    "        # First step: train the model with a trial-invariant stimulus effect\n",
    "        trainer.train(\n",
    "            include_stimulus=True,\n",
    "            include_coupling=False,\n",
    "            include_self_history=False,\n",
    "            fix_stimulus=True,\n",
    "            fix_latents=True,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        # Second step: train the model with a trial-varying stimulus effect\n",
    "        # trainer.make_optimizer(frozen_params=['sti_readout'])\n",
    "        trainer.make_optimizer(frozen_params=['sti_inhomo', ]) # We are fixing the trial-invariant stimulus effect\n",
    "        trainer.train(\n",
    "            include_stimulus=True,\n",
    "            include_coupling=False,\n",
    "            include_self_history=False,\n",
    "            fix_stimulus=False,\n",
    "            fix_latents=True,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "        # trainer.make_optimizer(frozen_params=['transformer_encoder', 'to_latent', 'token_converter'])\n",
    "        trainer.make_optimizer(frozen_params=['transformer_encoder', 'to_latent', 'token_converter',\n",
    "            'sti_readout', 'sti_decoder', 'sti_inhomo', 'cp_latents_readout', 'cp_time_varying_coef_offset', \n",
    "            'cp_beta_coupling', 'cp_weight_sending', 'cp_weight_receiving'])\n",
    "        # trainer.make_optimizer(frozen_params=[])\n",
    "        test_loss = trainer.train(\n",
    "            include_stimulus=True,\n",
    "            include_coupling=False,\n",
    "            include_self_history=True,\n",
    "            fix_stimulus=False,\n",
    "            fix_latents=True,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "        results_ablation[idata, irep] = test_loss\n",
    "np.save('/home/qix/user_data/EIF_simulation_dataset/results_ablation_wo_coupling.npy', results_ablation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 47/200 [00:03<00:12, 12.43it/s]\n",
      " 26%|██▌       | 51/200 [00:05<00:16,  9.06it/s]\n",
      " 10%|█         | 20/200 [00:02<00:22,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 53/200 [00:03<00:09, 15.61it/s]\n",
      " 20%|█▉        | 39/200 [00:04<00:19,  8.33it/s]\n",
      " 10%|█         | 21/200 [00:02<00:21,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 48/200 [00:03<00:11, 13.07it/s]\n",
      " 34%|███▎      | 67/200 [00:06<00:12, 10.77it/s]\n",
      " 11%|█         | 22/200 [00:02<00:19,  9.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 48/200 [00:03<00:11, 12.71it/s]\n",
      " 26%|██▌       | 51/200 [00:05<00:15,  9.86it/s]\n",
      " 12%|█▏        | 23/200 [00:02<00:21,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 48/200 [00:03<00:12, 12.44it/s]\n",
      " 37%|███▋      | 74/200 [00:08<00:13,  9.08it/s]\n",
      " 10%|█         | 20/200 [00:02<00:21,  8.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 70/200 [00:05<00:10, 12.98it/s]\n",
      " 16%|█▋        | 33/200 [00:03<00:16, 10.05it/s]\n",
      " 14%|█▍        | 28/200 [00:03<00:19,  8.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 79/200 [00:05<00:08, 14.02it/s]\n",
      " 10%|█         | 20/200 [00:02<00:19,  9.16it/s]\n",
      " 10%|▉         | 19/200 [00:02<00:21,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 67/200 [00:05<00:10, 12.89it/s]\n",
      " 34%|███▎      | 67/200 [00:07<00:14,  9.25it/s]\n",
      " 16%|█▌        | 31/200 [00:03<00:17,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 59/200 [00:04<00:11, 12.12it/s]\n",
      " 32%|███▏      | 64/200 [00:06<00:13,  9.82it/s]\n",
      " 12%|█▏        | 24/200 [00:03<00:23,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 71/200 [00:05<00:09, 13.86it/s]\n",
      " 15%|█▌        | 30/200 [00:03<00:17,  9.88it/s]\n",
      " 20%|██        | 41/200 [00:05<00:20,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [00:19<00:11,  1.63it/s]\n",
      "100%|██████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      " 22%|██▏       | 11/50 [00:15<00:54,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [00:19<00:10,  1.64it/s]\n",
      " 90%|█████████ | 45/50 [00:38<00:04,  1.16it/s]\n",
      " 36%|███▌      | 18/50 [00:24<00:43,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [00:21<00:11,  1.50it/s]\n",
      " 98%|█████████▊| 49/50 [00:41<00:00,  1.19it/s]\n",
      " 22%|██▏       | 11/50 [00:15<00:55,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [00:18<00:11,  1.67it/s]\n",
      "100%|██████████| 50/50 [00:45<00:00,  1.09it/s]\n",
      " 26%|██▌       | 13/50 [00:22<01:04,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [00:22<00:12,  1.43it/s]\n",
      "100%|██████████| 50/50 [00:42<00:00,  1.17it/s]\n",
      " 18%|█▊        | 9/50 [00:12<00:58,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "# Without neuron's post-spike effects\n",
    "results_ablation = np.zeros((len(datasets), nrep))\n",
    "\n",
    "for idata, data_to_use in enumerate(datasets):\n",
    "    for irep in range(nrep):\n",
    "\n",
    "        trainer = Trainer(data_to_use, ckp_path, params_set[idata])\n",
    "        \n",
    "        # First step: train the model with a trial-invariant stimulus effect\n",
    "        trainer.train(\n",
    "            include_stimulus=True,\n",
    "            include_coupling=False,\n",
    "            include_self_history=False,\n",
    "            fix_stimulus=True,\n",
    "            fix_latents=True,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        # Second step: train the model with a trial-varying stimulus effect\n",
    "        # trainer.make_optimizer(frozen_params=['sti_readout'])\n",
    "        trainer.make_optimizer(frozen_params=['sti_inhomo', ]) # We are fixing the trial-invariant stimulus effect\n",
    "        test_loss = trainer.train(\n",
    "            include_stimulus=True,\n",
    "            include_coupling=False,\n",
    "            include_self_history=False,\n",
    "            fix_stimulus=False,\n",
    "            fix_latents=True,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "        trainer.make_optimizer(frozen_params=['transformer_encoder', 'to_latent', 'token_converter'])\n",
    "        # trainer.make_optimizer(frozen_params=[])\n",
    "        trainer.train(\n",
    "            include_stimulus=True,\n",
    "            include_coupling=True,\n",
    "            include_self_history=False,\n",
    "            fix_stimulus=False,\n",
    "            fix_latents=True,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "        results_ablation[idata, irep] = test_loss\n",
    "np.save('/home/qix/user_data/EIF_simulation_dataset/results_ablation_wo_post_spike.npy', results_ablation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 47/200 [00:03<00:10, 14.92it/s]\n",
      "  4%|▍         | 9/200 [00:00<00:14, 13.09it/s]\n",
      " 13%|█▎        | 26/200 [00:02<00:17,  9.96it/s]\n",
      " 32%|███▏      | 63/200 [00:06<00:14,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 51/200 [00:03<00:08, 16.59it/s]\n",
      " 23%|██▎       | 46/200 [00:04<00:13, 11.17it/s]\n",
      "  9%|▉         | 18/200 [00:02<00:21,  8.47it/s]\n",
      " 28%|██▊       | 57/200 [00:06<00:15,  8.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 47/200 [00:02<00:09, 15.96it/s]\n",
      "  7%|▋         | 14/200 [00:01<00:17, 10.82it/s]\n",
      " 45%|████▌     | 90/200 [00:09<00:11,  9.52it/s]\n",
      " 29%|██▉       | 58/200 [00:06<00:15,  9.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 52/200 [00:03<00:10, 14.39it/s]\n",
      " 37%|███▋      | 74/200 [00:06<00:10, 11.59it/s]\n",
      "  9%|▉         | 18/200 [00:01<00:16, 11.17it/s]\n",
      " 28%|██▊       | 55/200 [00:05<00:14, 10.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 51/200 [00:03<00:09, 14.90it/s]\n",
      " 11%|█         | 22/200 [00:01<00:15, 11.52it/s]\n",
      " 22%|██▏       | 43/200 [00:04<00:16,  9.41it/s]\n",
      " 28%|██▊       | 57/200 [00:06<00:15,  9.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 68/200 [00:04<00:09, 14.35it/s]\n",
      " 33%|███▎      | 66/200 [00:06<00:12, 10.58it/s]\n",
      " 12%|█▏        | 23/200 [00:02<00:19,  9.14it/s]\n",
      " 28%|██▊       | 56/200 [00:05<00:15,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 76/200 [00:05<00:08, 14.00it/s]\n",
      " 44%|████▎     | 87/200 [00:07<00:09, 11.62it/s]\n",
      "  7%|▋         | 14/200 [00:01<00:22,  8.42it/s]\n",
      " 28%|██▊       | 56/200 [00:06<00:15,  9.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 64/200 [00:04<00:09, 13.86it/s]\n",
      " 42%|████▎     | 85/200 [00:08<00:11, 10.26it/s]\n",
      "  9%|▉         | 18/200 [00:01<00:16, 10.92it/s]\n",
      " 28%|██▊       | 55/200 [00:05<00:15,  9.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 70/200 [00:04<00:09, 14.32it/s]\n",
      " 38%|███▊      | 77/200 [00:06<00:10, 11.54it/s]\n",
      " 32%|███▏      | 64/200 [00:06<00:14,  9.16it/s]\n",
      " 28%|██▊       | 55/200 [00:06<00:16,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 68/200 [00:04<00:08, 16.25it/s]\n",
      " 36%|███▋      | 73/200 [00:06<00:10, 11.93it/s]\n",
      "  9%|▉         | 18/200 [00:01<00:17, 10.52it/s]\n",
      " 28%|██▊       | 56/200 [00:05<00:13, 10.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [00:19<00:11,  1.63it/s]\n",
      "100%|██████████| 50/50 [00:38<00:00,  1.29it/s]\n",
      " 24%|██▍       | 12/50 [00:15<00:50,  1.32s/it]\n",
      " 32%|███▏      | 16/50 [00:20<00:44,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [00:19<00:10,  1.68it/s]\n",
      "100%|██████████| 50/50 [00:40<00:00,  1.22it/s]\n",
      " 28%|██▊       | 14/50 [00:17<00:46,  1.28s/it]\n",
      " 26%|██▌       | 13/50 [00:17<00:49,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [00:19<00:09,  1.70it/s]\n",
      "100%|██████████| 50/50 [00:38<00:00,  1.30it/s]\n",
      " 32%|███▏      | 16/50 [00:20<00:44,  1.31s/it]\n",
      " 26%|██▌       | 13/50 [00:16<00:48,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [00:20<00:10,  1.61it/s]\n",
      "100%|██████████| 50/50 [00:38<00:00,  1.29it/s]\n",
      " 20%|██        | 10/50 [00:13<00:53,  1.33s/it]\n",
      " 32%|███▏      | 16/50 [00:21<00:45,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [00:19<00:10,  1.67it/s]\n",
      "100%|██████████| 50/50 [00:40<00:00,  1.25it/s]\n",
      " 18%|█▊        | 9/50 [00:12<00:56,  1.37s/it]\n",
      " 26%|██▌       | 13/50 [00:17<00:48,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "# Transformer -> RNN\n",
    "results_ablation = np.zeros((len(datasets), nrep))\n",
    "\n",
    "for idata, data_to_use in enumerate(datasets):\n",
    "    for irep in range(nrep):\n",
    "\n",
    "        trainer = Trainer(data_to_use, ckp_path, params_set[idata])\n",
    "        \n",
    "        # First step: train the model with a trial-invariant stimulus effect\n",
    "        trainer.train(\n",
    "            include_stimulus=True,\n",
    "            include_coupling=False,\n",
    "            include_self_history=False,\n",
    "            fix_stimulus=True,\n",
    "            fix_latents=True,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        # Second step: train the model with a trial-varying stimulus effect\n",
    "        # trainer.make_optimizer(frozen_params=['sti_readout'])\n",
    "        trainer.make_optimizer(frozen_params=['sti_inhomo', ]) # We are fixing the trial-invariant stimulus effect\n",
    "        trainer.train(\n",
    "            include_stimulus=True,\n",
    "            include_coupling=False,\n",
    "            include_self_history=False,\n",
    "            fix_stimulus=False,\n",
    "            fix_latents=True,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "        trainer.make_optimizer(frozen_params=['transformer_encoder', 'to_latent', 'token_converter'])\n",
    "        # trainer.make_optimizer(frozen_params=[])\n",
    "        trainer.train(\n",
    "            include_stimulus=True,\n",
    "            include_coupling=True,\n",
    "            include_self_history=False,\n",
    "            fix_stimulus=False,\n",
    "            fix_latents=True,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "        # trainer.make_optimizer(frozen_params=['transformer_encoder', 'to_latent', 'token_converter'])\n",
    "        trainer.make_optimizer(frozen_params=['transformer_encoder', 'to_latent', 'token_converter',\n",
    "            'sti_readout', 'sti_decoder', 'sti_inhomo', 'cp_latents_readout', 'cp_time_varying_coef_offset', \n",
    "            'cp_beta_coupling', 'cp_weight_sending', 'cp_weight_receiving'])\n",
    "        # trainer.make_optimizer(frozen_params=[])\n",
    "        test_loss = trainer.train(\n",
    "            include_stimulus=True,\n",
    "            include_coupling=True,\n",
    "            include_self_history=True,\n",
    "            fix_stimulus=False,\n",
    "            fix_latents=True,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "        results_ablation[idata, irep] = test_loss\n",
    "np.save('/home/qix/user_data/EIF_simulation_dataset/results_ablation_rnn.npy', results_ablation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qix/anaconda3/envs/allen/lib/python3.9/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8/200 [00:04<01:50,  1.73it/s]\n",
      "/home/qix/FC-GPFA/model_trainer.py:316: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(self.temp_best_model_path))\n",
      " 24%|██▎       | 47/200 [00:34<01:51,  1.38it/s]\n",
      "  4%|▎         | 7/200 [00:06<03:04,  1.05it/s]\n",
      "  6%|▌         | 12/200 [00:11<03:01,  1.04it/s]\n",
      "/home/qix/anaconda3/envs/allen/lib/python3.9/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8/200 [00:04<01:40,  1.90it/s]\n",
      " 18%|█▊        | 37/200 [00:27<02:00,  1.35it/s]\n",
      "  6%|▌         | 11/200 [00:10<02:57,  1.07it/s]\n",
      "  6%|▌         | 12/200 [00:12<03:09,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "# Low-rank -> full-rank\n",
    "# results_ablation = np.zeros((len(datasets), nrep))\n",
    "\n",
    "# for idata, data_to_use in enumerate(datasets):\n",
    "#     for irep in range(nrep):\n",
    "\n",
    "#         trainer = Trainer(data_to_use, ckp_path, params_set[idata])\n",
    "        \n",
    "#         # First step: train the model with a trial-invariant stimulus effect\n",
    "#         trainer.train(\n",
    "#             include_stimulus=True,\n",
    "#             include_coupling=False,\n",
    "#             include_self_history=False,\n",
    "#             fix_stimulus=True,\n",
    "#             fix_latents=True,\n",
    "#             verbose=verbose,\n",
    "#         )\n",
    "#         # Second step: train the model with a trial-varying stimulus effect\n",
    "#         # trainer.make_optimizer(frozen_params=['sti_readout'])\n",
    "#         trainer.make_optimizer(frozen_params=['sti_inhomo', ]) # We are fixing the trial-invariant stimulus effect\n",
    "#         trainer.train(\n",
    "#             include_stimulus=True,\n",
    "#             include_coupling=False,\n",
    "#             include_self_history=False,\n",
    "#             fix_stimulus=False,\n",
    "#             fix_latents=True,\n",
    "#             verbose=verbose,\n",
    "#         )\n",
    "\n",
    "#         trainer.make_optimizer(frozen_params=['transformer_encoder', 'to_latent', 'token_converter'])\n",
    "#         # trainer.make_optimizer(frozen_params=[])\n",
    "#         trainer.train(\n",
    "#             include_stimulus=True,\n",
    "#             include_coupling=True,\n",
    "#             include_self_history=False,\n",
    "#             fix_stimulus=False,\n",
    "#             fix_latents=True,\n",
    "#             verbose=verbose,\n",
    "#         )\n",
    "\n",
    "#         # trainer.make_optimizer(frozen_params=['transformer_encoder', 'to_latent', 'token_converter'])\n",
    "#         trainer.make_optimizer(frozen_params=['transformer_encoder', 'to_latent', 'token_converter',\n",
    "#             'sti_readout', 'sti_decoder', 'sti_inhomo', 'cp_latents_readout', 'cp_time_varying_coef_offset', \n",
    "#             'cp_beta_coupling', 'cp_weight_sending', 'cp_weight_receiving'])\n",
    "#         # trainer.make_optimizer(frozen_params=[])\n",
    "#         test_loss = trainer.train(\n",
    "#             include_stimulus=True,\n",
    "#             include_coupling=True,\n",
    "#             include_self_history=True,\n",
    "#             fix_stimulus=False,\n",
    "#             fix_latents=True,\n",
    "#             verbose=verbose,\n",
    "#         )\n",
    "\n",
    "#         results_ablation[idata, irep] = test_loss\n",
    "# np.save('/home/qix/user_data/EIF_simulation_dataset/results_ablation_full_rank.npy', results_ablation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset\tFull Model\tW/o Encoder\tW/o Coupling\tW/o post spike\tRNN\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Data 1\t0.20055 (0.00017)\t0.20231 (0.00029)\t0.20430 (0.00079)\t0.20728 (0.00027)\t0.20215 (0.00036)\n",
      "Data 2\t0.25223 (0.00008)\t0.25344 (0.00012)\t0.25621 (0.00012)\t0.26715 (0.00046)\t0.25244 (0.00017)\n",
      "Data 3\t0.05674 (0.00005)\t0.05735 (0.00004)\t0.05735 (0.00005)\t0.05776 (0.00001)\t0.05683 (0.00004)\n"
     ]
    }
   ],
   "source": [
    "# Load results from different models\n",
    "results_full = np.load('/home/qix/user_data/EIF_simulation_dataset/results_ablation_full_model.npy')\n",
    "results_wo_encoder = np.load('/home/qix/user_data/EIF_simulation_dataset/results_ablation_wo_encoder.npy') \n",
    "results_wo_coupling = np.load('/home/qix/user_data/EIF_simulation_dataset/results_ablation_wo_coupling.npy')\n",
    "results_wo_post_spike = np.load('/home/qix/user_data/EIF_simulation_dataset/results_ablation_wo_post_spike.npy')\n",
    "results_rnn = np.load('/home/qix/user_data/EIF_simulation_dataset/results_ablation_rnn.npy')\n",
    "\n",
    "# Calculate mean and sem for each model and dataset\n",
    "def mean_sem(data):\n",
    "    return f\"{data.mean():.5f} ({data.std()/np.sqrt(len(data)):.5f})\"\n",
    "\n",
    "# Create table rows\n",
    "table_rows = []\n",
    "for i in range(len(datasets)):\n",
    "    row = [\n",
    "        mean_sem(results_full[i,:]),\n",
    "        mean_sem(results_wo_encoder[i,:]), \n",
    "        mean_sem(results_wo_coupling[i,:]),\n",
    "        mean_sem(results_wo_post_spike[i,:]),\n",
    "        mean_sem(results_rnn[i,:])\n",
    "    ]\n",
    "    table_rows.append(row)\n",
    "\n",
    "# Print table\n",
    "print(\"Dataset\\tFull Model\\tW/o Encoder\\tW/o Coupling\\tW/o post spike\\tRNN\")\n",
    "print(\"-\"*100)\n",
    "for i, row in enumerate(table_rows):\n",
    "    print(f\"Data {i+1}\\t{row[0]}\\t{row[1]}\\t{row[2]}\\t{row[3]}\\t{row[4]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test different bin size in Transformer encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for all ablation experiments\n",
    "verbose = False\n",
    "# datasets = [synthetic_GLM_dataloader, synthetic_EIF_dataloader]\n",
    "datasets = [synthetic_GLM_dataloader, synthetic_EIF_dataloader, real_dataloader_fast]\n",
    "nrep = 1\n",
    "ckp_path = '/home/qix/user_data/VAETransformer_checkpoint_ablation'\n",
    "\n",
    "params_set = {}\n",
    "params_set[0] = {\n",
    "    # B-spline basis\n",
    "    'num_B_spline_basis': 10,\n",
    "    # Transformer VAE's settings\n",
    "    'downsample_factor': 10,\n",
    "    'transformer_num_layers': 2,\n",
    "    'transformer_d_model': 128,\n",
    "    'transformer_dim_feedforward': 512,\n",
    "    'transformer_vae_output_dim': 8,\n",
    "    'transformer_dropout': 0.0,\n",
    "    'transformer_nhead': 1,\n",
    "    'stimulus_nfactor': 2,\n",
    "    'stimulus_decoder_inter_dim_factor': 2,\n",
    "    'beta': 1.0,\n",
    "    'use_area_specific_decoder': True,\n",
    "    'use_area_specific_encoder': True,\n",
    "    'use_cls': False,\n",
    "    # Coupling's settings\n",
    "    'coupling_basis_peaks_max': 7,\n",
    "    'coupling_basis_num': 3,\n",
    "    'coupling_nsubspace': 1,\n",
    "    'use_self_coupling': True,\n",
    "    # Coupling strength latent's settings\n",
    "    'K_sigma2': 1.0,\n",
    "    'K_tau': 100,\n",
    "    'coupling_strength_nlatent': 1,\n",
    "    # Self-history's settings\n",
    "    'self_history_basis_peaks_max': 2,\n",
    "    'self_history_basis_num': 3,\n",
    "    'self_history_basis_nonlinear': 0.7,\n",
    "    # Penalty settings\n",
    "    'penalty_smoothing_spline': 1e3,\n",
    "    'penalty_coupling_subgroup': 1e-5,\n",
    "    'penalty_diff_loading': None,\n",
    "    'penalty_loading_similarity': None,\n",
    "    # Training settings\n",
    "    'batch_size': 64,\n",
    "    'sample_latent': False,\n",
    "    'lr': 1e-3,\n",
    "    'epoch_warm_up': 0,\n",
    "    'epoch_patience': 3,\n",
    "    'epoch_max': 200,\n",
    "    'tol': 1e-5,\n",
    "    'weight_decay': 0,\n",
    "    'lr_transformer': 1e-4,\n",
    "    'lr_sti': 1e-2,\n",
    "    'lr_cp': 1e-2,\n",
    "    'lr_self_history': 1e-2,\n",
    "}\n",
    "\n",
    "params_set[1] = {\n",
    "    # B-spline basis\n",
    "    'num_B_spline_basis': 20,\n",
    "    # Transformer VAE's settings\n",
    "    'downsample_factor': 10,\n",
    "    'transformer_num_layers': 2,\n",
    "    'transformer_d_model': 128,\n",
    "    'transformer_dim_feedforward': 512,\n",
    "    'transformer_vae_output_dim': 16,\n",
    "    'transformer_dropout': 0.0,\n",
    "    'transformer_nhead': 1,\n",
    "    'stimulus_nfactor': 1,\n",
    "    'stimulus_decoder_inter_dim_factor': 2,\n",
    "    'beta': 1.0,\n",
    "    'use_area_specific_decoder': True,\n",
    "    'use_area_specific_encoder': True,\n",
    "    'use_cls': False,\n",
    "    # Coupling's settings\n",
    "    'coupling_basis_peaks_max': 5,\n",
    "    'coupling_basis_num': 3,\n",
    "    'coupling_nsubspace': 1,\n",
    "    'use_self_coupling': True,\n",
    "    # Coupling strength latent's settings\n",
    "    'K_sigma2': 1.0,\n",
    "    'K_tau': 100,\n",
    "    'coupling_strength_nlatent': 1,\n",
    "    # Self-history's settings\n",
    "    'self_history_basis_peaks_max': 1.5,\n",
    "    'self_history_basis_num': 3,\n",
    "    'self_history_basis_nonlinear': 1,\n",
    "    # Penalty settings\n",
    "    'penalty_smoothing_spline': 1e3,\n",
    "    'penalty_coupling_subgroup': 1e-5,\n",
    "    'penalty_diff_loading': None,\n",
    "    'penalty_loading_similarity': None,\n",
    "    # Training settings\n",
    "    'batch_size': 64,\n",
    "    'sample_latent': False,\n",
    "    'lr': 1e-3,\n",
    "    'epoch_warm_up': 0,\n",
    "    'epoch_patience': 3,\n",
    "    'epoch_max': 200,\n",
    "    'tol': 1e-5,\n",
    "    'weight_decay': 0,\n",
    "    'lr_transformer': 1e-4,\n",
    "    'lr_sti': 1e-2,\n",
    "    'lr_cp': 1e-2,\n",
    "    'lr_self_history': 1e-2,\n",
    "}\n",
    "\n",
    "params_set[2] = {\n",
    "    # B-spline basis\n",
    "    'num_B_spline_basis': 10,\n",
    "    # Transformer VAE's settings\n",
    "    'downsample_factor': 10,\n",
    "    'transformer_num_layers': 2,\n",
    "    'transformer_d_model': 128,\n",
    "    'transformer_dim_feedforward': 512,\n",
    "    'transformer_vae_output_dim': 12,\n",
    "    'transformer_dropout': 0.0,\n",
    "    'transformer_nhead': 1,\n",
    "    'stimulus_nfactor': 2,\n",
    "    'stimulus_decoder_inter_dim_factor': 2,\n",
    "    'beta': 1.0,\n",
    "    'use_area_specific_decoder': True,\n",
    "    'use_area_specific_encoder': True,\n",
    "    'use_cls': False,\n",
    "    # Coupling's settings\n",
    "    'coupling_basis_peaks_max': 7,\n",
    "    'coupling_basis_num': 3,\n",
    "    'coupling_nsubspace': 1,\n",
    "    'use_self_coupling': True,\n",
    "    # Coupling strength latent's settings\n",
    "    'K_sigma2': 1.0,\n",
    "    'K_tau': 100,\n",
    "    'coupling_strength_nlatent': 1,\n",
    "    # Self-history's settings\n",
    "    'self_history_basis_peaks_max': 1.5,\n",
    "    'self_history_basis_num': 3,\n",
    "    'self_history_basis_nonlinear': 1,\n",
    "    # Penalty settings\n",
    "    'penalty_smoothing_spline': 1e3,\n",
    "    'penalty_coupling_subgroup': 1e-5,\n",
    "    'penalty_diff_loading': None,\n",
    "    'penalty_loading_similarity': None,\n",
    "    # Training settings\n",
    "    'batch_size': 64,\n",
    "    'sample_latent': False,\n",
    "    'lr': 1e-3,\n",
    "    'epoch_warm_up': 0,\n",
    "    'epoch_patience': 3,\n",
    "    'epoch_max': 50,\n",
    "    'tol': 1e-5,\n",
    "    'weight_decay': 0,\n",
    "    'lr_transformer': 1e-4,\n",
    "    'lr_sti': 1e-2,\n",
    "    'lr_cp': 1e-2,\n",
    "    'lr_self_history': 1e-2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [00:32<01:31,  2.48s/it]\n",
      "/home/qix/FC-GPFA/model_trainer.py:316: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(self.temp_best_model_path))\n",
      " 52%|█████▏    | 26/50 [01:38<01:30,  3.78s/it]\n",
      " 28%|██▊       | 14/50 [01:17<03:19,  5.55s/it]\n",
      " 16%|█▌        | 8/50 [00:47<04:09,  5.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [00:30<01:27,  2.36s/it]\n",
      " 80%|████████  | 40/50 [02:05<00:31,  3.14s/it]\n",
      " 14%|█▍        | 7/50 [00:37<03:47,  5.30s/it]\n",
      " 16%|█▌        | 8/50 [00:44<03:53,  5.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [00:28<01:22,  2.23s/it]\n",
      " 92%|█████████▏| 46/50 [02:11<00:11,  2.86s/it]\n",
      " 14%|█▍        | 7/50 [00:35<03:40,  5.12s/it]\n",
      " 18%|█▊        | 9/50 [00:57<04:21,  6.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [00:35<01:31,  2.54s/it]\n",
      " 70%|███████   | 35/50 [01:45<00:45,  3.02s/it]\n",
      " 14%|█▍        | 7/50 [00:34<03:33,  4.97s/it]\n",
      " 18%|█▊        | 9/50 [00:43<03:17,  4.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [00:27<01:16,  2.08s/it]\n",
      " 50%|█████     | 25/50 [01:21<01:21,  3.25s/it]\n",
      " 14%|█▍        | 7/50 [00:34<03:32,  4.94s/it]\n",
      " 16%|█▌        | 8/50 [00:40<03:30,  5.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [00:29<01:25,  2.30s/it]\n",
      " 58%|█████▊    | 29/50 [01:22<00:59,  2.84s/it]\n",
      " 12%|█▏        | 6/50 [00:29<03:35,  4.91s/it]\n",
      " 18%|█▊        | 9/50 [00:42<03:14,  4.75s/it]\n"
     ]
    }
   ],
   "source": [
    "downsample_factor_list = [1, 2, 5, 10, 20, 40]\n",
    "results_time_bin_size = np.zeros((len(downsample_factor_list), len(datasets), nrep))\n",
    "\n",
    "for idownsample, downsample_factor in enumerate(downsample_factor_list):\n",
    "    for idata, data_to_use in enumerate(datasets):\n",
    "        if idata != 2:\n",
    "            continue\n",
    "        for irep in range(nrep):\n",
    "            params_set[idata]['downsample_factor'] = downsample_factor\n",
    "            trainer = Trainer(data_to_use, ckp_path, params_set[idata])\n",
    "            \n",
    "            # First step: train the model with a trial-invariant stimulus effect\n",
    "            trainer.train(\n",
    "                include_stimulus=True,\n",
    "                include_coupling=False,\n",
    "                include_self_history=False,\n",
    "                fix_stimulus=True,\n",
    "                fix_latents=True,\n",
    "                verbose=verbose,\n",
    "            )\n",
    "            # Second step: train the model with a trial-varying stimulus effect\n",
    "            # trainer.make_optimizer(frozen_params=['sti_readout'])\n",
    "            trainer.make_optimizer(frozen_params=['sti_inhomo', ]) # We are fixing the trial-invariant stimulus effect\n",
    "            trainer.train(\n",
    "                include_stimulus=True,\n",
    "                include_coupling=False,\n",
    "                include_self_history=False,\n",
    "                fix_stimulus=False,\n",
    "                fix_latents=True,\n",
    "                verbose=verbose,\n",
    "            )\n",
    "\n",
    "            trainer.make_optimizer(frozen_params=['transformer_encoder', 'to_latent', 'token_converter'])\n",
    "            # trainer.make_optimizer(frozen_params=[])\n",
    "            trainer.train(\n",
    "                include_stimulus=True,\n",
    "                include_coupling=True,\n",
    "                include_self_history=False,\n",
    "                fix_stimulus=False,\n",
    "                fix_latents=True,\n",
    "                verbose=verbose,\n",
    "            )\n",
    "\n",
    "            # trainer.make_optimizer(frozen_params=['transformer_encoder', 'to_latent', 'token_converter'])\n",
    "            trainer.make_optimizer(frozen_params=['transformer_encoder', 'to_latent', 'token_converter',\n",
    "                'sti_readout', 'sti_decoder', 'sti_inhomo', 'cp_latents_readout', 'cp_time_varying_coef_offset', \n",
    "                'cp_beta_coupling', 'cp_weight_sending', 'cp_weight_receiving'])\n",
    "            # trainer.make_optimizer(frozen_params=[])\n",
    "            test_loss = trainer.train(\n",
    "                include_stimulus=True,\n",
    "                include_coupling=True,\n",
    "                include_self_history=True,\n",
    "                fix_stimulus=False,\n",
    "                fix_latents=True,\n",
    "                verbose=verbose,\n",
    "            )\n",
    "\n",
    "            results_time_bin_size[idownsample, idata, irep] = test_loss\n",
    "\n",
    "np.save('/home/qix/user_data/EIF_simulation_dataset/results_time_bin_size_real_data.npy', results_time_bin_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both results_time_bin_size and results_time_bin_size_real_data\n",
    "results_simulated = np.load('/home/qix/user_data/EIF_simulation_dataset/results_time_bin_size.npy')\n",
    "results_real = np.load('/home/qix/user_data/EIF_simulation_dataset/results_time_bin_size_real_data.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "downsample_factor_list = np.array([1, 2, 5, 10, 20, 40])\n",
    "plt.plot(downsample_factor_list*2, results_simulated[:, 0, :].mean(axis=1)-np.min(results_simulated[:, 0, :].mean(axis=1)))\n",
    "plt.plot(downsample_factor_list*2, results_simulated[:, 1, :].mean(axis=1)-np.min(results_simulated[:, 1, :].mean(axis=1)))\n",
    "plt.plot(downsample_factor_list*2, results_real[:, 2, :].mean(axis=1)-np.min(results_real[:, 2, :].mean(axis=1)))\n",
    "plt.xlabel('Time bin size')\n",
    "plt.ylabel('Test loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time Bin Size (ms)</th>\n",
       "      <th>Simulated Data 1</th>\n",
       "      <th>Simulated Data 2</th>\n",
       "      <th>Real Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2.43e+04</td>\n",
       "      <td>3.39e+04</td>\n",
       "      <td>6.39e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1.09e+04</td>\n",
       "      <td>3.07e+04</td>\n",
       "      <td>6.30e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1.43e+02</td>\n",
       "      <td>9.56e+01</td>\n",
       "      <td>1.42e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>2.21e+03</td>\n",
       "      <td>6.03e+04</td>\n",
       "      <td>1.35e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>80</td>\n",
       "      <td>7.59e+03</td>\n",
       "      <td>4.45e+04</td>\n",
       "      <td>7.29e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time Bin Size (ms) Simulated Data 1 Simulated Data 2 Real Data\n",
       "0                   2         2.43e+04         3.39e+04  6.39e+04\n",
       "1                   4         1.09e+04         3.07e+04  6.30e+04\n",
       "2                  10         1.43e+02         9.56e+01  1.42e+04\n",
       "3                  20         0.00e+00         0.00e+00  0.00e+00\n",
       "4                  40         2.21e+03         6.03e+04  1.35e+04\n",
       "5                  80         7.59e+03         4.45e+04  7.29e+03"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a table showing mean and std of results across different time bin sizes\n",
    "downsample_factor_list = np.array([1, 2, 5, 10, 20, 40])\n",
    "time_bin_sizes = downsample_factor_list * 2\n",
    "\n",
    "# Calculate total number of bins\n",
    "# total_bins = ((len(real_dataloader_fast.test_batches)-1)*real_dataloader_fast.batch_size + 26)*352*250\n",
    "total_bins = 148720000\n",
    "\n",
    "# Calculate means multiplied by total_bins and subtract minimum\n",
    "sim_means_1 = results_simulated[:, 0, :].mean(axis=1) * total_bins\n",
    "sim_means_1 = sim_means_1 - np.min(sim_means_1)\n",
    "sim_means_2 = results_simulated[:, 1, :].mean(axis=1) * total_bins \n",
    "sim_means_2 = sim_means_2 - np.min(sim_means_2)\n",
    "real_means = results_real[:, 2, :].mean(axis=1) * total_bins\n",
    "real_means = real_means - np.min(real_means)\n",
    "\n",
    "# Create pandas DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "results_table = pd.DataFrame({\n",
    "    'Time Bin Size (ms)': time_bin_sizes,\n",
    "    'Simulated Data 1': [f'{m:.2e}' for m in sim_means_1],\n",
    "    'Simulated Data 2': [f'{m:.2e}' for m in sim_means_2], \n",
    "    'Real Data': [f'{m:.2e}' for m in real_means]\n",
    "})\n",
    "\n",
    "# Display the table\n",
    "display(results_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
